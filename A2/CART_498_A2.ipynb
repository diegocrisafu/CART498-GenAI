{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1ElswUP2h1iimRXb0UPyCB3hvwJX0uMxA","authorship_tag":"ABX9TyMWTORLtp4nSRovgJa86o6Y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JB0sK4VzDA7-","executionInfo":{"status":"ok","timestamp":1738213431507,"user_tz":300,"elapsed":38500,"user":{"displayName":"Diego Cris","userId":"04160676058858891225"}},"outputId":"8c98cca2-2053-4791-a8be-fa1349c4b87a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Found nouns.txt at: /content/drive/MyDrive/A2/nouns.txt\n","Loaded 55191 nouns. First 5 nouns: ['a', 'aa', 'aaa', 'aachen', 'aalborg']\n","P+7 transformation saved to P+7.txt\n","P+10 transformation saved to P+10.txt\n","\n","Sample P+7 lines:\n","\n","Lilac aalto birdhouse on the wirework,\n","lilac aalto druthers inactiveness aalto midshipman chokepoint\n","Iambus hawaii tried inactiveness my wayside to beacon freehold.\n","Lilac aalto worry on aalto hookup,\n","lilac aalto knitter from some oldwench fashioned bookend\n","\n","Sample P+10 lines:\n","\n","Liliales aardwolf birdnest on the wiring,\n","liliales aardwolf dryad inadequateness aardwolf midsummer choking\n","Ibadan hawfinch tried inadequateness my wbn to beadle freelance.\n","Liliales aardwolf worse on aardwolf hooligan,\n","liliales aardwolf knitwork from some oleaceae fashioned bookie\n"]}],"source":["############################################\n","# 0. MOUNT GOOGLE DRIVE\n","############################################\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","import torch\n","import re\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","\n","############################################\n","# 1. FUNCTION: LOAD NOUNS FROM FILE\n","############################################\n","def load_nouns_from_file(filepath):\n","    \"\"\"\n","    Reads a list of nouns from a text file (one noun per line),\n","    sorts them alphabetically, and returns as a list.\n","    \"\"\"\n","    noun_list = []\n","    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n","        for line in f:\n","            noun = line.strip()\n","            # Skip blank lines\n","            if noun:\n","                noun_list.append(noun)\n","    # Sort them before returning\n","    noun_list = sorted(noun_list)\n","    return noun_list\n","\n","############################################\n","# 2. Specify the Path to nouns.txt in A2 Folder\n","############################################\n","# Example: /content/drive/MyDrive/A2/nouns.txt\n","filepath = \"/content/drive/MyDrive/A2/nouns.txt\"\n","\n","# Check if the file exists for debugging\n","if os.path.exists(filepath):\n","    print(f\"Found nouns.txt at: {filepath}\")\n","else:\n","    print(f\"Could NOT find file at: {filepath}\")\n","\n","############################################\n","# 3. Load the Nouns from the File\n","############################################\n","noun_list = load_nouns_from_file(filepath)\n","print(f\"Loaded {len(noun_list)} nouns. First 5 nouns:\", noun_list[:5])\n","\n","############################################\n","# 4. GPT-2 Setup (Optional for debugging)\n","############################################\n","model_name = \"gpt2\"\n","tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","model = GPT2LMHeadModel.from_pretrained(model_name)\n","model.eval()\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","def get_topk_next_tokens(model, tokenizer, prompt, top_k=10):\n","    \"\"\"\n","    Debug function: Returns top-k next tokens for GPT-2 after `prompt`.\n","    (Not used in final output, just for potential internal logging.)\n","    \"\"\"\n","    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n","    with torch.no_grad():\n","        outputs = model(input_ids)\n","\n","    logits = outputs.logits[0, -1, :]\n","    probs = torch.softmax(logits, dim=-1)\n","    top_tokens = torch.topk(probs, top_k)\n","\n","    results = []\n","    for token_id, prob_val in zip(top_tokens.indices, top_tokens.values):\n","        token_str = tokenizer.decode(\n","            [token_id.item()],\n","            skip_special_tokens=True,\n","            clean_up_tokenization_spaces=True\n","        )\n","        token_str = token_str.strip()\n","        results.append((token_str, prob_val.item()))\n","    return results\n","\n","############################################\n","# 5. THE TRANSFORMATION FUNCTIONS\n","############################################\n","def p_plus_n_transform(line, noun_list, n=7):\n","    \"\"\"\n","    For each word that appears in 'noun_list' (case-insensitive),\n","    replace it with the noun that is n entries ahead in the list (wrapping around).\n","    Returns:\n","      - new_line: the transformed line\n","      - changed_nouns: list of (original_word, chosen_word) pairs\n","    \"\"\"\n","    words = line.split()\n","    new_words = []\n","    changed_nouns = []\n","\n","    for word in words:\n","        # Separate punctuation from the end\n","        punctuation = \"\"\n","        match = re.match(r\"^(.*?)(\\W*)$\", word)\n","        if match:\n","            main_word = match.group(1)\n","            punctuation = match.group(2)\n","        else:\n","            main_word = word\n","\n","        lower_word = main_word.lower()\n","        if lower_word in noun_list:\n","            try:\n","                index = noun_list.index(lower_word)\n","            except ValueError:\n","                # If not found, keep original\n","                new_words.append(word)\n","                continue\n","\n","            # Move n steps forward in noun_list, wrapping around\n","            next_index = (index + n) % len(noun_list)\n","            new_noun = noun_list[next_index]\n","\n","            # Preserve capitalization\n","            if main_word and main_word[0].isupper():\n","                new_noun = new_noun.capitalize()\n","\n","            new_words.append(new_noun + punctuation)\n","            changed_nouns.append((main_word, new_noun))\n","        else:\n","            # Keep as is\n","            new_words.append(word)\n","\n","    new_line = \" \".join(new_words)\n","    return new_line, changed_nouns\n","\n","def generate_pn_version(poem_lines, noun_list, n=7):\n","    \"\"\"\n","    Applies p_plus_n_transform to each line,\n","    returns:\n","      - transformed_lines\n","      - all_changes: combined (original, chosen) for entire poem\n","    \"\"\"\n","    transformed_lines = []\n","    all_changes = []\n","\n","    for line in poem_lines:\n","        transformed_line, changed_nouns = p_plus_n_transform(line, noun_list, n=n)\n","        transformed_lines.append(transformed_line)\n","        all_changes.extend(changed_nouns)\n","\n","    return transformed_lines, all_changes\n","\n","############################################\n","# 6. Sample Poem Lines\n","############################################\n","poem_lines = [\n","    \"Like a bird on the wire,\",\n","    \"like a drunk in a midnight choir\",\n","    \"I have tried in my way to be free.\",\n","    \"Like a worm on a hook,\",\n","    \"like a knight from some old fashioned book\",\n","    \"I have saved all my ribbons for thee.\",\n","    \"If I, if I have been unkind,\",\n","    \"I hope that you can just let it go by.\",\n","    \"If I, if I have been untrue\",\n","    \"I hope you know it was never to you.\",\n","    \"Like a baby, stillborn,\",\n","    \"like a beast with his horn\",\n","    \"I have torn everyone who reached out for me.\",\n","    \"But I swear by this song\",\n","    \"and by all that I have done wrong\",\n","    \"I will make it all up to thee.\",\n","    \"I saw a beggar leaning on his wooden crutch,\",\n","    \"he said to me, \\\"You must not ask for so much.\\\"\",\n","    \"And a pretty woman leaning in her darkened door,\",\n","    \"she cried to me, \\\"Hey, why not ask for more?\\\"\",\n","    \"Oh like a bird on the wire,\",\n","    \"like a drunk in a midnight choir\",\n","    \"I have tried in my way to be free.\"\n","]\n","\n","############################################\n","# 7. Generate P+7 and P+X\n","############################################\n","p7_lines, p7_changes = generate_pn_version(poem_lines, noun_list, n=7)\n","x_value = 10\n","px_lines, px_changes = generate_pn_version(poem_lines, noun_list, n=x_value)\n","\n","############################################\n","# 8. Write P+7 to a File\n","############################################\n","with open(\"P+7.txt\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(\"=== P+7 Version of 'Bird on the Wire' ===\\n\\n\")\n","    # Poem lines\n","    for line in p7_lines:\n","        f.write(line + \"\\n\")\n","    # Summaries\n","    f.write(\"\\n--- Changed Nouns (Original -> Chosen) ---\\n\")\n","    for orig, chosen in p7_changes:\n","        f.write(f\"{orig} -> {chosen}\\n\")\n","\n","print(\"P+7 transformation saved to P+7.txt\")\n","\n","############################################\n","# 9. Write P+X to a File\n","############################################\n","px_filename = f\"P+{x_value}.txt\"\n","with open(px_filename, \"w\", encoding=\"utf-8\") as f:\n","    f.write(f\"=== P+{x_value} Version of 'Bird on the Wire' ===\\n\\n\")\n","    # Poem lines\n","    for line in px_lines:\n","        f.write(line + \"\\n\")\n","    # Summaries\n","    f.write(\"\\n--- Changed Nouns (Original -> Chosen) ---\\n\")\n","    for orig, chosen in px_changes:\n","        f.write(f\"{orig} -> {chosen}\\n\")\n","\n","print(f\"P+{x_value} transformation saved to {px_filename}\")\n","\n","############################################\n","# 10. Optional: Print a sample to console\n","############################################\n","print(\"\\nSample P+7 lines:\\n\")\n","for line in p7_lines[:5]:\n","    print(line)\n","\n","print(f\"\\nSample P+{x_value} lines:\\n\")\n","for line in px_lines[:5]:\n","    print(line)\n"]}]}